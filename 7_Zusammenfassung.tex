\chapter{Conclusion} \label{conclusion}

%%%%%%%%%%%%%%%%%%%%%%%%%
% Was war das Ziel?
% Was habe ich getan?
% Was wurde erreicht?
% Was lernen wir daraus?
% "Woran kÃ¶nnte man weiter forschen?"
%%%%%%%%%%%%%%%%%%%%%%%%%

- For very very small inputs, original is better because of less overhead
- Translation is better than original, but manual optimizations always outperforms translation
- If the problem has overlapping subproblems, the speed up is large because translation implements automatic memoization


Without doubt, any problem specific optimization can outperform our automatic generated solution. We cannot exploit domain specific properties that constrain the solution space. Lets take again for example the fibonacci-function. By its definition, it is completely sufficient to keep only the last two numbers 

Nevertheless this does not render our solution less valuable: Problem specific optimizations may exists, but usually it is hard do uncover and exploit them. In practice, the effort to come up with an optimal solution is not worth all the effort when a "good enough" solution would also fit the use-case. Furthermore, the maintainability of a short and simple, declarative piece of code is much higher than the optimized version, that exploits subtle properties of the problem, the database-system or uses other nifty tweaks.


Static analysis is flexible, limitations sound hard, but are not so bad. Generalization to other conditionals is easy possible, implementation is well structured in phases and easy expandable.

The translation is many magnitudes faster than the original naive recursive function. The original fib-function can be called with max fib(23), while the translation handles still fib(100) within ca. 300ms on the same machine. Problem specific optimized solutions still always wins.


%Exmaple: threaded binary tree for iterative tree traversal to keep stack size manageable => smart, but hard to find!
\section*{Acknowledgements}
Thanks to Chris, Denis, Grust, proofreader, ...